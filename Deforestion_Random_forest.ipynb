{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8994f4d",
      "metadata": {
        "id": "d8994f4d"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "# !pip install rasterio\n",
        "import rasterio as rio\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score , classification_report\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66bc2e2f",
      "metadata": {
        "id": "66bc2e2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "708d9a28-752d-43da-9d35-298e08819346"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0                                           Filename  Label  \\\n",
            "0       16257                      AnnualCrop/AnnualCrop_142.jpg      0   \n",
            "1        3297  HerbaceousVegetation/HerbaceousVegetation_2835...      2   \n",
            "2       17881               PermanentCrop/PermanentCrop_1073.jpg      6   \n",
            "3        2223                      Industrial/Industrial_453.jpg      4   \n",
            "4        4887  HerbaceousVegetation/HerbaceousVegetation_1810...      2   \n",
            "\n",
            "              ClassName  \n",
            "0            AnnualCrop  \n",
            "1  HerbaceousVegetation  \n",
            "2         PermanentCrop  \n",
            "3            Industrial  \n",
            "4  HerbaceousVegetation  \n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "\n",
        "data_dir = \"/content/drive/MyDrive/Colab Notebooks/EuroSAT\"\n",
        "csv_path = os.path.join(data_dir, \"train.csv\")\n",
        "train_csv = \"/content/drive/MyDrive/Colab Notebooks/EuroSAT/train.csv\"\n",
        "# test_csv  = \"/content/drive/MyDrive/Colab Notebooks/EuroSAT/test.csv\"\n",
        "# val_csv   = \"/content/drive/MyDrive/Colab Notebooks/EuroSAT/validate.csv\"\n",
        "\n",
        "df = pd.read_csv(train_csv)\n",
        "print(df.head())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
        "\n",
        "\n",
        "data_dir = \"/content/drive/MyDrive/Colab Notebooks/EuroSAT\"\n",
        "forest_path = os.path.join(data_dir, \"Forest\", img_rel)\n",
        "deforest_path = os.path.join(data_dir, \"Deforested\", img_rel)\n",
        "\n",
        "df['BinaryLabel'] = df['ClassName'].apply(\n",
        "    lambda x: 0 if x == \"Forest\" else 1\n",
        ")\n",
        "\n",
        "# Using CNN preinstaled feature extractoe\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, pooling='avg')\n",
        "\n",
        "def extract_features(img_path):\n",
        "    img = image.load_img(img_path, target_size=(128,128))\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "    features = base_model.predict(x, verbose=0)\n",
        "    return features.flatten()\n",
        "\n",
        "X, y = [], []\n",
        "\n",
        "for idx, row in df.iterrows():\n",
        "    img_rel = row['Filename']\n",
        "\n",
        "\n",
        "\n",
        "    if os.path.exists(forest_path):\n",
        "        img_path = forest_path\n",
        "    elif os.path.exists(deforest_path):\n",
        "        img_path = deforest_path\n",
        "    else:\n",
        "        print(\"Missing:\", img_rel)\n",
        "        continue\n",
        "    feat = extract_features(img_path)\n",
        "    X.append(feat)\n",
        "    y.append(row['Label'])\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "print(\"Feature matrix shape:\", X.shape)\n",
        "print(\"Labels shape:\", y.shape)\n"
      ],
      "metadata": {
        "id": "zQ6Cm5fLcSF_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0318ba9-6afa-422e-9d11-17da6329ebd0"
      },
      "id": "zQ6Cm5fLcSF_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-932043826.py:11: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  base_model = MobileNetV2(weights='imagenet', include_top=False, pooling='avg')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature matrix shape: (18900, 1280)\n",
            "Labels shape: (18900,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input"
      ],
      "metadata": {
        "id": "XRim5J8k8Y36"
      },
      "id": "XRim5J8k8Y36",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
        "\n",
        "\n",
        "\n",
        "data_dir = \"/content/drive/MyDrive/Colab Notebooks/EuroSAT\"\n",
        "\n",
        "# Binary labels: 0=Forest, 1=Deforested\n",
        "df['BinaryLabel'] = df['ClassName'].apply(lambda x: 0 if x == \"Forest\" else 1)\n",
        "\n",
        "# Here we are reducing dataset\n",
        "df = df.sample(2000, random_state=42).reset_index(drop=True)\n",
        "print(\"Using subset size:\", len(df))\n",
        "\n",
        "\n",
        "#  Feature extraction going on\n",
        "\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, pooling='avg')\n",
        "\n",
        "def extract_features(img_path):\n",
        "    img = image.load_img(img_path, target_size=(128,128))\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "    return base_model.predict(x, verbose=0).flatten()\n",
        "\n",
        "\n",
        "#looping through rows\n",
        "\n",
        "X, y = [], []\n",
        "\n",
        "for idx, row in df.iterrows():\n",
        "    img_rel = row['Filename']\n",
        "\n",
        "    # Fixing  path logic: don't duplicate \"Forest\"\n",
        "    if row['ClassName'] == \"Forest\":\n",
        "        img_path = os.path.join(data_dir, img_rel)\n",
        "    else:\n",
        "        img_path = os.path.join(data_dir, \"Deforested\", img_rel)\n",
        "\n",
        "    if not os.path.exists(img_path):\n",
        "        print(\"Missing:\", img_path)\n",
        "        continue\n",
        "\n",
        "    feat = extract_features(img_path)\n",
        "    X.append(feat)\n",
        "    y.append(row['BinaryLabel'])\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "print(\" Features extracted\")\n",
        "print(\"Feature matrix shape:\", X.shape)\n",
        "print(\"Labels shape:\", y.shape)\n",
        "print(\"Unique binary labels:\", np.unique(y))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrQa9TP58P8-",
        "outputId": "da70f116-c54a-4dbd-d5f9-142068cee2df"
      },
      "id": "qrQa9TP58P8-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using subset size: 2000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2612510847.py:21: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  base_model = MobileNetV2(weights='imagenet', include_top=False, pooling='avg')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Features extracted\n",
            "Feature matrix shape: (2000, 1280)\n",
            "Labels shape: (2000,)\n",
            "Unique binary labels: [0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "\n",
        "clf_stage1 = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
        "clf_stage1.fit(X_train, y_train)\n",
        "\n",
        "y_pred = clf_stage1.predict(X_test)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o81YAEhCEn-9",
        "outputId": "73ecd08e-b1e2-42cd-a5a8-acd1f42b16a3"
      },
      "id": "o81YAEhCEn-9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9575\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.66      0.78        47\n",
            "           1       0.96      1.00      0.98       353\n",
            "\n",
            "    accuracy                           0.96       400\n",
            "   macro avg       0.96      0.83      0.88       400\n",
            "weighted avg       0.96      0.96      0.95       400\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            " [[ 31  16]\n",
            " [  1 352]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "#  Subtype classification (only on deforested)\n",
        "\n",
        "\n",
        "# Filter only deforested samples\n",
        "mask_deforested = (y == 1)   # binary label = 1 means deforested\n",
        "X_def = X[mask_deforested]\n",
        "y_def = df.loc[mask_deforested, \"Label\"].values\n",
        "\n",
        "print(\"Deforested feature matrix shape:\", X_def.shape)\n",
        "print(\"Subtype labels shape:\", y_def.shape)\n",
        "print(\"Unique subtypes:\", np.unique(y_def))\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_def, y_def, test_size=0.2, random_state=42, stratify=y_def\n",
        ")\n",
        "\n",
        "# Train Random Forest (multi-class)\n",
        "clf_stage2 = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
        "clf_stage2.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "y_pred = clf_stage2.predict(X_test)\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(\"Stage-2 Accuracy:\", acc)\n",
        "\n",
        "print(\"\\nStage-2 Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"\\nStage-2 Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVvozg2HE92y",
        "outputId": "dca9f870-e29b-4ff5-fe62-31484de87e95"
      },
      "id": "dVvozg2HE92y",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deforested feature matrix shape: (1764, 1280)\n",
            "Subtype labels shape: (1764,)\n",
            "Unique subtypes: [0 2 3 4 5 6 7 8 9]\n",
            "Stage-2 Accuracy: 0.8328611898016998\n",
            "\n",
            "Stage-2 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      1.00      0.86        48\n",
            "           2       0.81      0.80      0.80        44\n",
            "           3       0.80      0.57      0.67        35\n",
            "           4       0.87      0.87      0.87        38\n",
            "           5       0.95      0.70      0.81        30\n",
            "           6       0.81      0.81      0.81        31\n",
            "           7       0.89      0.98      0.93        43\n",
            "           8       0.68      0.74      0.71        38\n",
            "           9       0.98      0.91      0.94        46\n",
            "\n",
            "    accuracy                           0.83       353\n",
            "   macro avg       0.84      0.82      0.82       353\n",
            "weighted avg       0.84      0.83      0.83       353\n",
            "\n",
            "\n",
            "Stage-2 Confusion Matrix:\n",
            "[[48  0  0  0  0  0  0  0  0]\n",
            " [ 0 35  0  1  0  5  0  2  1]\n",
            " [ 2  3 20  1  0  0  1  8  0]\n",
            " [ 0  0  1 33  0  0  4  0  0]\n",
            " [ 1  4  0  0 21  1  0  3  0]\n",
            " [ 3  0  1  2  0 25  0  0  0]\n",
            " [ 0  0  0  1  0  0 42  0  0]\n",
            " [ 6  1  3  0  0  0  0 28  0]\n",
            " [ 3  0  0  0  1  0  0  0 42]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "\n",
        "# Reuse your pretrained feature extractor\n",
        "def extract_features(img_path, base_model):\n",
        "    img = image.load_img(img_path, target_size=(128,128))\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "    features = base_model.predict(x, verbose=0)\n",
        "    return features.flatten().reshape(1, -1)\n",
        "\n",
        "# Pipeline function\n",
        "def predict_pipeline(img_path, base_model, clf_stage1, clf_stage2, subtype_mapping):\n",
        "    # Extract features\n",
        "    feat = extract_features(img_path, base_model)\n",
        "\n",
        "    # Stage 1: Forest vs. Deforested\n",
        "    stage1_pred = clf_stage1.predict(feat)[0]\n",
        "    if stage1_pred == 0:\n",
        "        return \"Forest\"\n",
        "    else:\n",
        "        # Stage 2: Which type of deforested\n",
        "        subtype_pred = clf_stage2.predict(feat)[0]\n",
        "        subtype_name = subtype_mapping.get(subtype_pred, f\"Subtype-{subtype_pred}\")\n",
        "        return f\"Deforested ‚Üí {subtype_name}\"\n"
      ],
      "metadata": {
        "id": "3mNCqoFks5h_"
      },
      "id": "3mNCqoFks5h_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing\n",
        "\n",
        "test_img1= \"/content/drive/MyDrive/Colab Notebooks/EuroSAT/Deforested/Residential/Residential_2.jpg\"\n",
        "test_img2= \"/content/drive/MyDrive/Colab Notebooks/EuroSAT/Deforested/Industrial/Industrial_9.jpg\"\n",
        "\n",
        "result = predict_pipeline(test_img2, base_model, clf_stage1, clf_stage2, subtype_mapping)\n",
        "print(\"Prediction:\", result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHC5lfAMGM62",
        "outputId": "25c64691-a1b6-4bb9-ac24-f7488b13bb42"
      },
      "id": "UHC5lfAMGM62",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: Deforested ‚Üí Industrial\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(clf_stage1, \"/content/drive/MyDrive/Colab Notebooks/clf_stage1.pkl\")\n",
        "joblib.dump(clf_stage2, \"/content/drive/MyDrive/Colab Notebooks/clf_stage2.pkl\")\n",
        "\n",
        "print(\"‚úÖ Models saved as clf_stage1.pkl and clf_stage2.pkl\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W32LvPhYGbdM",
        "outputId": "210e8f16-6ce1-4f22-d4cc-f241054b6441"
      },
      "id": "W32LvPhYGbdM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Models saved as clf_stage1.pkl and clf_stage2.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Check if file exists\n",
        "print(os.path.exists(\"/content/drive/MyDrive/Colab Notebooks/clf_stage1.pkl\"))\n",
        "print(os.path.exists(\"/content/drive/MyDrive/Colab Notebooks/clf_stage2.pkl\"))\n",
        "\n",
        "# List contents of folder\n",
        "!ls -lh \"/content/drive/MyDrive/Colab Notebooks\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMOSJIxwJirZ",
        "outputId": "3da941a6-cb40-41c0-ed66-8bb934b431c3"
      },
      "id": "pMOSJIxwJirZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n",
            "total 15M\n",
            "-rw------- 1 root root 1.6M Aug 30 13:33  clf_stage1.pkl\n",
            "-rw------- 1 root root  13M Aug 30 13:33  clf_stage2.pkl\n",
            "-rw------- 1 root root  14K Aug 30 13:40  deforesration_Detect.py\n",
            "-rw------- 1 root root  16K Aug 30 13:40 'Deforestion Random forest.ipynb'\n",
            "drwx------ 4 root root 4.0K Aug 30 05:37  EuroSAT\n",
            "-rw------- 1 root root 1.2K Aug 30 13:21  Untitled0.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
        "import joblib   # if you want to save/load your models\n",
        "\n",
        "# -------------------------\n",
        "# Load pretrained CNN\n",
        "# -------------------------\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, pooling='avg')\n",
        "\n",
        "# Load trained classifiers (after you save them with joblib.dump)\n",
        "# clf_stage1 = joblib.load(\"clf_stage1.pkl\")\n",
        "# clf_stage2 = joblib.load(\"clf_stage2.pkl\")\n",
        "\n",
        "# For demo ‚Äì assuming you already have them in memory\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf_stage1 = joblib.load(\"/content/drive/MyDrive/Colab Notebooks/clf_stage1.pkl\")\n",
        "clf_stage2 = joblib.load(\"/content/drive/MyDrive/Colab Notebooks/clf_stage2.pkl\")\n",
        "\n",
        "\n",
        "\n",
        "# Mapping (make sure to use your actual mapping dictionary)\n",
        "subtype_mapping = {\n",
        "    0: \"AnnualCrop\",\n",
        "    2: \"HerbaceousVegetation\",\n",
        "    3: \"Industrial\",\n",
        "    4: \"Pasture\",\n",
        "    5: \"PermanentCrop\",\n",
        "    6: \"Residential\",\n",
        "    7: \"River\",\n",
        "    8: \"SeaLake\",\n",
        "    9: \"Highway\"\n",
        "}\n",
        "\n",
        "# -------------------------\n",
        "# Feature extraction function\n",
        "# -------------------------\n",
        "def extract_features(img):\n",
        "    img = img.resize((128, 128))   # same as training\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "    features = base_model.predict(x, verbose=0)\n",
        "    return features.flatten()\n",
        "\n",
        "# -------------------------\n",
        "# Prediction pipeline\n",
        "# -------------------------\n",
        "def predict_pipeline(uploaded_img):\n",
        "    # Extract features\n",
        "    features = extract_features(uploaded_img).reshape(1, -1)\n",
        "\n",
        "    # Stage-1: Forest vs Deforested\n",
        "    stage1_pred = clf_stage1.predict(features)[0]\n",
        "\n",
        "    if stage1_pred == 0:\n",
        "        return \"üå≤ Forest\"\n",
        "    else:\n",
        "        # Stage-2: Subtype classification\n",
        "        subtype_pred = clf_stage2.predict(features)[0]\n",
        "        subtype_name = subtype_mapping.get(subtype_pred, \"Unknown\")\n",
        "        return f\"üåæ Deforested ‚Üí {subtype_name}\"\n",
        "\n",
        "# -------------------------\n",
        "# Streamlit UI\n",
        "# -------------------------\n",
        "st.set_page_config(page_title=\"Deforestation Classifier\", page_icon=\"üåç\")\n",
        "st.title(\"üõ∞Ô∏è Deforestation Detection\")\n",
        "st.write(\"Upload a satellite image to classify whether it's **Forest** or **Deforested**, and if deforested ‚Üí subtype.\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Upload an image\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    img = Image.open(uploaded_file).convert(\"RGB\")\n",
        "    st.image(img, caption=\"Uploaded Image\", use_column_width=True)\n",
        "\n",
        "    if st.button(\"üîç Predict\"):\n",
        "        result = predict_pipeline(img)\n",
        "        st.success(f\"Prediction: {result}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1skNLsQYNYWu",
        "outputId": "5ec65fd4-fbc2-4f2c-a161-1a408725b086"
      },
      "id": "1skNLsQYNYWu",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.49.1-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.2.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.8.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.27.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.49.1-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.49.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4091904811.py:13: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  base_model = MobileNetV2(weights='imagenet', include_top=False, pooling='avg')\n",
            "2025-08-30 13:42:03.855 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-30 13:42:03.856 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-30 13:42:04.039 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.12/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n",
            "2025-08-30 13:42:04.040 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-30 13:42:04.041 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-30 13:42:04.047 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-30 13:42:04.051 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-30 13:42:04.054 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-30 13:42:04.055 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-30 13:42:04.058 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-30 13:42:04.060 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-30 13:42:04.063 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-30 13:42:04.064 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-30 13:42:04.066 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "gjvlG98gNhq8",
        "outputId": "523a0e4a-69eb-41bd-f858-9ee6621fc520"
      },
      "id": "gjvlG98gNhq8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (ipython-input-1609277159.py, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-1609277159.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    streamlit run /usr/local/lib/python3.12/dist-packages/colab_kernel_launcher.py\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hA0kdiQdOA95"
      },
      "id": "hA0kdiQdOA95",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}